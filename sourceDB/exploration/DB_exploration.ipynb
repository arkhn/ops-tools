{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Base Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy.dialects import oracle\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "import psycopg2\n",
    "import mysql.connector as msql\n",
    "import cx_Oracle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "import dash_cytoscape as cyto\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import no_update\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "import networkx as nx\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_w_header(query):\n",
    "    with engine.connect() as con:\n",
    "        statement = text(query)\n",
    "        res = con.execute(statement)\n",
    "        df = pd.DataFrame(res)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def query_wo_header(query):\n",
    "    with engine.connect() as con:\n",
    "\n",
    "        statement = text(query)\n",
    "        df = pd.read_sql(statement, con)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ego_graph(G, n, radius=1, center=True, undirected=False, distance=None):\n",
    "    if undirected:\n",
    "        if distance is not None:\n",
    "            sp, _ = nx.single_source_dijkstra(\n",
    "                G.to_undirected(), n, cutoff=radius, weight=distance\n",
    "            )\n",
    "        else:\n",
    "            sp = dict(\n",
    "                nx.single_source_shortest_path_length(\n",
    "                    G.to_undirected(), n, cutoff=radius\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        if distance is not None:\n",
    "            sp, _ = nx.single_source_dijkstra(G, n, cutoff=radius, weight=distance)\n",
    "        else:\n",
    "            sp = dict(nx.single_source_shortest_path_length(G, n, cutoff=radius))\n",
    "\n",
    "    H = G.subgraph(sp).copy()\n",
    "    if not center:\n",
    "        H.remove_node(n)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"config.json\") as json_data_file:\n",
    "        data = json.load(json_data_file)\n",
    "except FileNotFoundError:\n",
    "        print('config.json file missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = data[\"database\"][\"connector\"]\n",
    "sqluser = data[\"database\"][\"user\"]\n",
    "sqlpass = data[\"database\"][\"passwd\"]\n",
    "host = data[\"database\"][\"host\"]\n",
    "port = data[\"database\"][\"port\"]\n",
    "dbname = data[\"database\"][\"db\"]\n",
    "database = data[\"database\"][\"database\"]\n",
    "driver = data[\"database\"][\"driver\"]\n",
    "schema_name = data[\"database\"][\"schema\"]\n",
    "\n",
    "connection = \"{}+{}://{}:{}@{}:{}/{}\".format(\n",
    "    driver, connector, sqluser, sqlpass, host, port, dbname\n",
    ")\n",
    "engine = create_engine(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries SQL\n",
    "#### All queries needed to run these notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database == \"postgres\":\n",
    "\n",
    "    # Query1: Discover schemas\n",
    "    query1_schemas = \"\"\" SELECT schema_name\n",
    "                 FROM information_schema.schemata; \n",
    "                 \"\"\"\n",
    "\n",
    "    # Query2: Show all tables and columns\n",
    "\n",
    "    query2_all_tables = \"\"\" select t.table_schema, t.table_name, c.column_name\n",
    "                    from information_schema.\"tables\" t\n",
    "                    join information_schema.\"columns\" c\n",
    "                    on t.table_name = c.table_name\n",
    "                    where t.TABLE_TYPE = 'BASE TABLE' \n",
    "                    \"\"\"\n",
    "\n",
    "    # Query3: All keys (primary and foreigner), and target tables\n",
    "\n",
    "    query3_all_keys = \"\"\"select kcu.constraint_schema, kcu.table_name, kcu.column_name , kcu.constraint_name, \n",
    "                kcu2.table_name as referenced_table, kcu2.column_name as  referenced_column\n",
    "                from information_schema.key_column_usage kcu \n",
    "                join information_schema.referential_constraints rc using(constraint_schema, constraint_name)\n",
    "                join information_schema.key_column_usage kcu2 \n",
    "                on kcu2.constraint_schema = rc.unique_constraint_schema \n",
    "                and kcu2.constraint_name  = rc.unique_constraint_name\n",
    "                and kcu2.ordinal_position = kcu.position_in_unique_constraint \n",
    "                \"\"\"\n",
    "\n",
    "    # Query4: First 10 lines from each table\n",
    "\n",
    "    query4_first10 = \"\"\" select * from {}.{} limit 10 \n",
    "    \"\"\"\n",
    "\n",
    "    # Query5: Columns Stats\n",
    "\n",
    "    query5_col_stats = \"\"\"select t.table_schema, t.table_name , c.column_name, c.data_type , stt.n_live_tup, (st.null_frac * stt.n_live_tup)/100\n",
    "                from information_schema.\"tables\" t\n",
    "                join information_schema.\"columns\" c\n",
    "                on t.table_name = c.table_name\n",
    "                left join pg_stat_all_tables stt\n",
    "                on stt.relname = t.table_name \n",
    "                left join pg_catalog.pg_stats st\n",
    "                on st. attname  = c.column_name and st.tablename = t.table_name \n",
    "                where t.TABLE_TYPE = 'BASE TABLE' \n",
    "                \"\"\"\n",
    "\n",
    "    # Query6: Columns commentaries\n",
    "\n",
    "    query6_col_comments = \"\"\"SELECT c.table_schema, c.table_name, c.column_name, pgd.description\n",
    "                FROM pg_catalog.pg_statio_all_tables as st\n",
    "                inner join pg_catalog.pg_description pgd \n",
    "                on pgd.objoid=st.relid\n",
    "                inner join information_schema.columns c \n",
    "                on (pgd.objsubid=c.ordinal_position\n",
    "                and c.table_schema=st.schemaname \n",
    "                and c.table_name=st.relname) \n",
    "                \"\"\"\n",
    "\n",
    "    # Query7: Tables commentaries - number of rows\n",
    "    query7_table_comments = \"\"\"select u1.schemaname, p1.relname, u1.n_live_tup, p2.description \n",
    "                from pg_stat_all_tables u1 \n",
    "                left join pg_Class p1\n",
    "                on u1.relname = p1.relname\n",
    "                left join pg_Description p2 \n",
    "                on p2.ObjOID = u1.relid\n",
    "                where p2.objsubid = 0\n",
    "                \"\"\"\n",
    "\n",
    "# TODO This is under consideration:\n",
    "#    query7 = \"\"\"select u1.schemaname, p1.relname, u1.n_live_tup, p2.description\n",
    "#                from pg_stat_all_tables u1\n",
    "#                left join pg_Class p1\n",
    "#                on u1.relname = p1.relname\n",
    "#                left join pg_Description p2\n",
    "#                on p2.ObjOID = p1.OID where ObjSubID = 0 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database == \"oracle\":\n",
    "\n",
    "    # Query1: Discover schemas\n",
    "\n",
    "    query1_schemas = \"\"\"select username as schema_name\n",
    "                from sys.all_users\n",
    "                order by username\n",
    "                \"\"\"\n",
    "\n",
    "    # Query2: Show all tables and columns\n",
    "\n",
    "    query2_all_tables = \"\"\"select owner, table_name , column_name \n",
    "                FROM ALL_TAB_COLUMNS \n",
    "                \"\"\"\n",
    "    # Query3: All keys (primary and foreigner), and target tables\n",
    "\n",
    "    query3_all_keys = \"\"\"SELECT uc_r.owner, uc_r.table_name, ucc_r.column_name, uc_r.constraint_name,\n",
    "                uc_p.constraint_name, uc_p.table_name, ucc_p.column_name\n",
    "                from all_constraints uc_r\n",
    "                join all_cons_columns ucc_r on ucc_r.constraint_name = uc_r.constraint_name\n",
    "                join all_constraints uc_p on uc_p.constraint_name = uc_r.r_constraint_name\n",
    "                join all_cons_columns ucc_p on ucc_p.constraint_name = uc_p.constraint_name\n",
    "                and ucc_p.position = ucc_r.position\n",
    "                where uc_r.constraint_type = 'R' \n",
    "                \"\"\"\n",
    "\n",
    "    # Query4: First 10 lines from each table\n",
    "\n",
    "    query4_first10 = \"\"\"select * from {}.{} WHERE ROWNUM <= 10 \n",
    "    \"\"\"\n",
    "\n",
    "    # Query5: Columns Stats\n",
    "\n",
    "    query5_col_stats = \"\"\"SELECT a.owner, ab_.TABLE_NAME, ab_.column_name as \"column\", ac.DATA_TYPE as Dtype, a.num_rows as \"nb_rows\", \n",
    "                ab_.num_nulls as \"null_count\"\n",
    "                FROM ALL_TABLES a\n",
    "                JOIN ALL_TAB_COL_STATISTICS ab_\n",
    "                ON a.table_name = ab_.table_name\n",
    "                JOIN all_tab_cols ac\n",
    "                ON ac.table_name = ab_.table_name AND ac.COLUMN_NAME = ab_.COLUMN_NAME \n",
    "                \"\"\"\n",
    "\n",
    "    # Query6: Columns commentaries\n",
    "\n",
    "    query6_col_comments = \"\"\"SELECT a.table_name, a.column_name, c.comments  \n",
    "                from ALL_TAB_COLS a\n",
    "                join ALL_COL_COMMENTS c\n",
    "                ON a.table_name = c.table_name AND a.COLUMN_NAME = c.COLUMN_NAME \n",
    "                \"\"\"\n",
    "\n",
    "    # Query7: Tables commentaries - number of rows\n",
    "\n",
    "    query7_table_comments = \"\"\"SELECT c.owner, c.table_name, abl.num_rows,c.comments  \n",
    "                from  ALL_TAB_COMMENTS c\n",
    "                JOIN ALL_TABLES abl\n",
    "                ON c.TABLE_NAME = abl.TABLE_NAME \n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database == \"mysql\":\n",
    "\n",
    "    # Query1: Discover schemas\n",
    "\n",
    "    query1_schemas = \"\"\"select SCHEMA_NAME from information_schema.SCHEMATA s\n",
    "    \"\"\"\n",
    "\n",
    "    # Query2: Show all tables and columns\n",
    "\n",
    "    query2_all_tables = \"\"\"select table_schema, table_name, column_name \n",
    "                from information_schema.`COLUMNS` c \n",
    "                \"\"\"\n",
    "    # Query3: All keys (primary and foreigner), and target tables\n",
    "\n",
    "    query3_all_keys = \"\"\"SELECT CONSTRAINT_SCHEMA, TABLE_NAME, COLUMN_NAME, CONSTRAINT_NAME, REFERENCED_TABLE_NAME, REFERENCED_COLUMN_NAME \n",
    "                FROM INFORMATION_SCHEMA.key_column_usage \n",
    "                \"\"\"\n",
    "\n",
    "    # Query4: First 10 lines from each table\n",
    "\n",
    "    query4_first10 = \"\"\"select * from {}.{} limit 10 \n",
    "    \"\"\"\n",
    "\n",
    "    # Query5: Columns Stats (#Fro MySql incomplete query)\n",
    "\n",
    "    query5_col_stats = \"\"\"SELECT c.table_schema, t.table_name, c.column_name, c.data_type, t.table_rows, t.table_rows\n",
    "                from information_schema.columns c\n",
    "                join information_schema.tables t\n",
    "                on c.table_name = t.table_name \n",
    "                \"\"\"\n",
    "\n",
    "    # Query6: Columns commentaries\n",
    "\n",
    "    query6_col_comments = \"\"\"select table_schema, table_name, column_name, column_comment\n",
    "                from information_schema.columns \n",
    "                \"\"\"\n",
    "\n",
    "    # Query7: Tables commentaries - number of rows\n",
    "\n",
    "    query7_table_comments = \"\"\"select table_schema, table_name, table_rows, table_comment\n",
    "                from information_schema.tables  \n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Discovering DataBase schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = list(query_w_header(query1_schemas)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema_name = input()\n",
    "schema_name = data['database']['schema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Info schema tables and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Obtain all the tables names and columns from information.schema.\n",
    "#### Schema name of the data base, example: mimiciii for MIMIC and classicmodels for the toy database (avoid systems folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two data frames are generated:\n",
    "\n",
    "    1. df_table: containing all table names and columns names (all database)\n",
    "    2. df_table_pk: containing all table names and columns names of only primary and foreig keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if schema_name != \"all\":\n",
    "\n",
    "    if database == \"postgres\":\n",
    "        query2_all_tables = \" \".join(\n",
    "            [query2_all_tables, \"\"\"and t.table_schema ='{}'\"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query3_all_keys = \" \".join(\n",
    "            [query3_all_keys, \"\"\"where kcu.constraint_schema ='{}'\"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query5_col_stats = \" \".join(\n",
    "            [query5_col_stats, \"\"\"and t.table_schema = '{}';\"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query7_table_comments = \" \".join(\n",
    "            [query7_table_comments, \"\"\"or u1.schemaname = '{}';\"\"\"]\n",
    "        ).format(schema_name)\n",
    "\n",
    "    elif database == \"mysql\":\n",
    "        query2_all_tables = \" \".join(\n",
    "            [query2_all_tables, \"\"\"where TABLE_SCHEMA ='{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query3_all_keys = \" \".join(\n",
    "            [query3_all_keys, \"\"\"where TABLE_SCHEMA ='{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query5_col_stats = \" \".join(\n",
    "            [query5_col_stats, \"\"\"where c.table_schema = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query6_col_comments = \" \".join(\n",
    "            [query6_col_comments, \"\"\"where table_schema = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query7_table_comments = \" \".join(\n",
    "            [query7_table_comments, \"\"\"where table_schema = '{}'; \"\"\"]\n",
    "        ).format(schema_name)\n",
    "\n",
    "    elif database == \"oracle\":\n",
    "        query2_all_tables = \" \".join(\n",
    "            [query2_all_tables, \"\"\"where owner = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query3_all_keys = \" \".join(\n",
    "            [query3_all_keys, \"\"\"AND uc_r.owner = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query5_col_stats = \" \".join(\n",
    "            [query5_col_stats, \"\"\"WHERE a.owner = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query6_col_comments = \" \".join(\n",
    "            [query6_col_comments, \"\"\"WHERE a.owner = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "        query7_table_comments = \" \".join(\n",
    "            [query7_table_comments, \"\"\"where c.owner = '{}' \"\"\"]\n",
    "        ).format(schema_name)\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = query_w_header(query2_all_tables)\n",
    "df_table.columns = [\"schema_name\", \"table_name\", \"column_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) If primary and foreig keys are used, the following query allows the selection of only those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tqdm(total=1) as progress:\n",
    "        df_table_pk = query_w_header(query3_all_keys)\n",
    "        progress.update()\n",
    "    print(progress.format_interval(progress.format_dict[\"elapsed\"]))\n",
    "except:\n",
    "    df_table_pk = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database == \"oracle\":\n",
    "    df_table_pk.columns = [\n",
    "        \"schema_name\",\n",
    "        \"table_name\",\n",
    "        \"column_name\",\n",
    "        \"key\",\n",
    "        \"key2\",\n",
    "        \"target\",\n",
    "        \"target_label\",\n",
    "    ]\n",
    "    df_table_pk.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    df_table_pk2 = df_table_pk.dropna(axis=0)\n",
    "    df_table_pk2.columns = [\n",
    "        \"schema\",\n",
    "        \"from\",\n",
    "        \"label\",\n",
    "        \"key\",\n",
    "        \"key2\",\n",
    "        \"target\",\n",
    "        \"target_label\",\n",
    "    ]\n",
    "    df_table_pk2.reset_index(inplace=True, drop=True)\n",
    "    df_table_pk2.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    df_table_pk.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "else:\n",
    "    df_table_pk.columns = [\n",
    "        \"schema_name\",\n",
    "        \"table_name\",\n",
    "        \"column_name\",\n",
    "        \"key2\",\n",
    "        \"target\",\n",
    "        \"target_label\",\n",
    "    ]\n",
    "    df_table_pk.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    df_table_pk2 = df_table_pk.dropna(axis=0)\n",
    "    df_table_pk2.columns = [\"schema\", \"from\", \"label\", \"key\", \"target\", \"target_label\"]\n",
    "    df_table_pk2.reset_index(inplace=True, drop=True)\n",
    "    df_table_pk2.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    df_table_pk.fillna(value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_pk.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3) Obtaining first 10 rows of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables = list(df_table.table_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_schema_table = (\n",
    "    df_table[[\"schema_name\", \"table_name\"]].set_index(\"table_name\").T.to_dict(\"list\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_tables = {}\n",
    "\n",
    "with tqdm(total=len(list_tables)) as progress:\n",
    "    for k, v in dict_schema_table.items():\n",
    "        try:\n",
    "            h = k\n",
    "            j = \"\".join(v)\n",
    "            df = pd.DataFrame()\n",
    "            #df = query_wo_header(query4_first10.format(j, k))\n",
    "            table_name = h + \"_rows\"\n",
    "            rows_tables[table_name] = df\n",
    "            progress.update()\n",
    "        except:\n",
    "            print(\"error ->\", j)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "print(progress.format_interval(progress.format_dict[\"elapsed\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Info columns per table (stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General stats from all data base, number of tables, number of columns, amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=1) as progress:\n",
    "    df = query_wo_header(query5_col_stats)\n",
    "    df.columns = [\n",
    "        \"schema_name\", \n",
    "        \"table_name\", \n",
    "        \"column_name\", \n",
    "        \"Dtype\", \n",
    "        \"nb_rows\", \n",
    "        \"null_count\"\n",
    "    ]\n",
    "    progress.update()\n",
    "print(progress.format_interval(progress.format_dict[\"elapsed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=1) as progress:\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i,\"nb_rows\"] != 0:\n",
    "            df.loc[i, \"percentage\"] = ((df.loc[i,\"nb_rows\"]-df.loc[i,\"null_count\"]) * 100)/ df.loc[i,\"nb_rows\"]\n",
    "            progress.update()\n",
    "        else:\n",
    "            df.loc[i,'percentage'] = 0\n",
    "    print(progress.format_interval(progress.format_dict[\"elapsed\"]))\n",
    "\n",
    "df.fillna(value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generation of .CSV files    \n",
    "    1. Column.csv: table name, column name, nb of filled rows, data type, completion %, primary/foreign key, table related (target) , target column name, exmple of data, comments (from information_schema).\n",
    "    2. Table.csv: names, number of rows, number of columns, primary key, # tables related), comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Column CSV generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_data(df, df_table_pk, rows_tables, query6_col_comments):\n",
    "\n",
    "    # generate the table backbone merging all columns stats (df) and keys information(df_table_pk)\n",
    "    columns_csv = pd.merge(\n",
    "        df, df_table_pk, how=\"left\", on=[\"schema_name\",\"table_name\", \"column_name\"]\n",
    "    )\n",
    "\n",
    "    # generate the columns preview (summary)\n",
    "    summary2_df = pd.DataFrame(columns=[\"table_name\", \"column_name\", \"example\"])\n",
    "\n",
    "    for i in rows_tables:\n",
    "        columnas = list(rows_tables[i])\n",
    "        for j in columnas:\n",
    "            a = list(rows_tables[i][j].head(5).unique())\n",
    "            dff7 = pd.DataFrame(\n",
    "                {\"table_name\": [i[:-5]], \"column_name\": [j], \"example\": [a]}\n",
    "            )\n",
    "            summary2_df = summary2_df.append(dff7, True)\n",
    "\n",
    "    # merge the columns preview with the first backbone\n",
    "    columns_csv = columns_csv.merge(\n",
    "        summary2_df, how=\"left\", on=[\"table_name\", \"column_name\"]\n",
    "    )\n",
    "\n",
    "    # obtain the columns commentaries\n",
    "    try:\n",
    "        df_table_comments = query_w_header(query6_col_comments)\n",
    "        df_table_comments.columns = [\n",
    "            \"table_name\",\n",
    "            \"column_name\",\n",
    "            \"comments\",\n",
    "        ]\n",
    "    except:\n",
    "        df_table_comments = pd.DataFrame(\n",
    "            columns=[\"table_name\", \"column_name\", \"comments\"]\n",
    "        )\n",
    "\n",
    "    # merge the columns commentaries with table backbone\n",
    "    columns_csv = columns_csv.merge(\n",
    "        df_table_comments, how=\"left\", on=[\"table_name\", \"column_name\"]\n",
    "    )\n",
    "    columns_csv.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "    return columns_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_csv = columns_data(df, df_table_pk, rows_tables, query6_col_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_csv.to_csv(\"columns_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Table CSV generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_data(columns, df_table_pk):\n",
    "\n",
    "    # obtain general table information through columns_csv analysis\n",
    "    # tables name, nb of columns\n",
    "    table_name = columns.groupby([\"schema_name\", \"table_name\"])[\"column_name\"].count()\n",
    "    table_name = pd.DataFrame(table_name)\n",
    "    table_name.reset_index(inplace=True)\n",
    "\n",
    "    # keys names\n",
    "    keys_list = (\n",
    "        columns.groupby([\"schema_name\", \"table_name\"])[\"key2\"]\n",
    "        .unique()\n",
    "        .apply(list)\n",
    "        .apply(lambda x: [i for i in x if str(i) != \"nan\"])\n",
    "    )\n",
    "    key_type = pd.DataFrame(keys_list)\n",
    "    key_type.reset_index(inplace=True)\n",
    "\n",
    "    # merging table name and nb of columns with key info\n",
    "    table_csv = table_name.merge(key_type, how=\"left\", on=[\"schema_name\", \"table_name\"])\n",
    "\n",
    "    # columns key name\n",
    "    key_list2 = (\n",
    "        df_table_pk.groupby([\"schema_name\", \"table_name\"])[\"column_name\"]\n",
    "        .unique()\n",
    "        .apply(list)\n",
    "        .apply(lambda x: [i for i in x if str(i) != \"nan\"])\n",
    "    )\n",
    "    key_name = pd.DataFrame(key_list2)\n",
    "    key_name.reset_index(inplace=True)\n",
    "\n",
    "    # merging of columns key name\n",
    "    table_csv = table_csv.merge(key_name, how=\"left\", on=[\"schema_name\", \"table_name\"])\n",
    "\n",
    "    # obtaining target tables\n",
    "    target_table = (\n",
    "        columns.groupby([\"schema_name\", \"table_name\"])[\"target\"]\n",
    "        .unique()\n",
    "        .apply(list)\n",
    "        .apply(lambda x: [i for i in x if str(i) != \"nan\"])\n",
    "    )\n",
    "    target = pd.DataFrame(target_table)\n",
    "    target.reset_index(inplace=True)\n",
    "\n",
    "    table_csv = table_csv.merge(target, how=\"left\", on=[\"schema_name\", \"table_name\"])\n",
    "\n",
    "    # obtaining table comments\n",
    "    try:\n",
    "        table_rows = query_w_header(query7_table_comments)\n",
    "        table_rows.columns = [\n",
    "            \"schema_name\",\n",
    "            \"table_name\",\n",
    "            \"table_rows\",\n",
    "            \"table_comment\",\n",
    "        ]\n",
    "    except:\n",
    "        table_rows = pd.DataFrame(\n",
    "            columns=[\"schema_name\", \"table_name\", \"table_rows\", \"table_comment\"]\n",
    "        )\n",
    "\n",
    "    # merging to final table\n",
    "    table_csv = table_csv.merge(\n",
    "        table_rows, how=\"left\", on=[\"schema_name\", \"table_name\"]\n",
    "    )\n",
    "\n",
    "    # if an oracle database is analysed, final table will have 9 columns, for other databases table info will have \n",
    "    # 8 columns\n",
    "    if len(table_csv.columns) == 8:\n",
    "\n",
    "        table_csv.columns = [\n",
    "            \"schema_name\",\n",
    "            \"table_name\",\n",
    "            \"nb_columns\",\n",
    "            \"keys\",\n",
    "            \"keys_columns\",\n",
    "            \"target_table\",\n",
    "            \"nb_rows\",\n",
    "            \"table_comments\",\n",
    "        ]\n",
    "        cols = [\n",
    "            \"schema_name\",\n",
    "            \"table_name\",\n",
    "            \"nb_columns\",\n",
    "            \"nb_rows\",\n",
    "            \"keys\",\n",
    "            \"keys_columns\",\n",
    "            \"target_table\",\n",
    "           \"table_comments\"\n",
    "        ]\n",
    "        \n",
    "        table_csv = table_csv[cols]\n",
    "    elif len(table_csv.columns) == 9:\n",
    "\n",
    "        table_csv.columns = [\n",
    "            \"schema_name\",\n",
    "            \"table_name\",\n",
    "            \"nb_columns\",\n",
    "            \"keys\",\n",
    "            \"keys2\",\n",
    "            \"keys_columns\",\n",
    "            \"target_table\",\n",
    "            \"nb_rows\",\n",
    "            \"table_comments\",\n",
    "        ]\n",
    "        cols = [\n",
    "            \"schema_name\",\n",
    "            \"table_name\",\n",
    "            \"nb_columns\",\n",
    "            \"nb_rows\",\n",
    "            \"keys\",\n",
    "            \"keys2\",\n",
    "            \"keys_columns\",\n",
    "            \"target_table\",\n",
    "            \"table_comments\",\n",
    "        ]\n",
    "        table_csv=table_csv[cols]\n",
    "\n",
    "    return table_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_csv = table_data(columns_csv, df_table_pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "table_csv.to_csv('tables_info.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) First impression DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of tables and their relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of schemas/owners\n",
    "print(\"Number of schemas =\", df_table.schema_name.nunique())\n",
    "# Number of tables\n",
    "print(\"Number of tables =\", df_table.table_name.nunique())\n",
    "# Number of unique columns names\n",
    "print(\"Number of unique columns = \", df_table.column_name.nunique())\n",
    "# Number of columns (including keys)\n",
    "print(\"Number of columns = \", df_table.column_name.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(np.array([['N째 Schemas', df_table.schema_name.nunique()],['N째 Tables', df_table.table_name.nunique()],['N째 unique columns', df_table.column_name.nunique()],['N째 columns', df_table.column_name.count()]]),columns = ['','Count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 3. Relative amount of data per table\n",
    "    Each big square represents a table, inside each of the columns and if the columns are important keys.\n",
    "    Each a column is a key, then the target table is indicated.\n",
    "    Color scaled indicators of column filling in percentage (amount of not-null data / total number of rows).\n",
    "    Uncomment if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_3 = px.treemap(\n",
    "#    columns_csv,\n",
    "#    path=[\"schema_name\", \"table_name\", \"column_name\", \"key2\"],\n",
    "#    color=\"percentage\",\n",
    "#    color_continuous_scale=\"RdBu\",\n",
    "#    color_continuous_midpoint=50,\n",
    "#)\n",
    "#\n",
    "#fig_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Table conections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database == \"postgres\":\n",
    "    df_table3 = (\n",
    "        df_table_pk2.groupby([\"schema\", \"from\", \"target\"])[\"label\"]\n",
    "        .apply(list)\n",
    "        .reset_index(name=\"keys\")\n",
    "    )\n",
    "\n",
    "    df_table3[\"size\"] = df_table3[\"keys\"].apply(lambda x: len(x))\n",
    "\n",
    "    df_table3 = df_table3.unstack().unstack().T\n",
    "    \n",
    "elif database == \"oracle\":\n",
    "    df_table_pk2[\"combined\"] = df_table_pk2.apply(\n",
    "        lambda x: list([x[\"key\"], x[\"key2\"]]), axis=1\n",
    "    )\n",
    "    df_table3 = (\n",
    "        df_table_pk2.groupby([\"schema\", \"from\", \"target\", \"label\"])[\"combined\"]\n",
    "        .apply(list)\n",
    "        .reset_index(name=\"keys\")\n",
    "    )\n",
    "\n",
    "    df_table3[\"size\"] = df_table3[\"keys\"].apply(lambda x: len(x))\n",
    "\n",
    "    df_table3 = df_table3.unstack().unstack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig5. Interactive Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstruction of the relationships is done with all the columns or the primary/foreign keys, according to the chose (primary/all).\n",
    "Relationship is reconstructed usign Networkx and interactively ploted in Dash/Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_table3, source=\"from\", target=\"target\", edge_attr=True)\n",
    "\n",
    "pos = nx.layout.spring_layout(G)\n",
    "\n",
    "elements = nx.cytoscape_data(G)\n",
    "\n",
    "nodes = elements[\"elements\"][\"nodes\"]\n",
    "\n",
    "palette = sns.color_palette(\n",
    "    None, len(nodes)\n",
    ")  # TODO Change color for schema and not nodes!\n",
    "\n",
    "col_swatch = list(palette.as_hex())\n",
    "\n",
    "\n",
    "for i in range(len(nodes)):\n",
    "    a = nodes[i][\"data\"][\"id\"]\n",
    "    b = {\"position\": {\"x\": 1000 * pos[a][0], \"y\": 1000 * pos[a][1]}}\n",
    "    nodes[i].update(b)\n",
    "for i in range(len(nodes)):\n",
    "    c = {\"selectable\": True}\n",
    "    nodes[i][\"data\"].update(c)\n",
    "edges = elements[\"elements\"][\"edges\"]\n",
    "\n",
    "for i in range(len(nodes)):\n",
    "    d = {\"color_node\": col_swatch[i], \"size\": 20}\n",
    "    nodes[i][\"data\"].update(d)\n",
    "\n",
    "elements_dash = nodes + edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylesheets = [\n",
    "    {\n",
    "        \"selector\": \"edge\",\n",
    "        \"style\": {\"color\": \"data(keys)\", \"line-color\": \"lightgray\", \"width\": 3},\n",
    "    },\n",
    "    {\n",
    "        \"selector\": \"node\",\n",
    "        \"style\": {\n",
    "            \"label\": \"data(id)\",\n",
    "            \"font-size\": 20,\n",
    "            \"background-color\": \"data(color_node)\",\n",
    "            \"line-color\": \"data(color_node)\",\n",
    "            \"width\": \"data(size)\",\n",
    "            \"height\": \"data(size)\",\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = {\"pre\": {\"border\": \"thin lightgrey solid\", \"overflowX\": \"scroll\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.SPACELAB])\n",
    "\n",
    "#### LAYOUT DASHBOARD ####\n",
    "\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        html.Div(\n",
    "            [\n",
    "                dbc.Row(\n",
    "                    [\n",
    "                        dbc.Col(\n",
    "                            [\n",
    "                                html.H1(\n",
    "                                    \"Data Base exploration\",\n",
    "                                    className=\"bg-primary text-white text-center\",\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div([dbc.Row([html.Br([])])]),\n",
    "        html.Div(\n",
    "            [\n",
    "                dbc.Row(\n",
    "                    [\n",
    "                        dbc.Col(width=1),\n",
    "                        dbc.Col(\n",
    "                            dbc.Container(\n",
    "                                [\n",
    "                                    dbc.Row(\n",
    "                                        [html.H5(\"Schema:\", className=\"text-info\")]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            dcc.Dropdown(\n",
    "                                                id=\"dpdn5\",\n",
    "                                                multi=True,\n",
    "                                                clearable=True,\n",
    "                                                options=[\n",
    "                                                    {\n",
    "                                                        \"label\": name,\n",
    "                                                        \"value\": name,\n",
    "                                                    }\n",
    "                                                    for name in list(\n",
    "                                                        columns_csv[\n",
    "                                                            \"schema_name\"\n",
    "                                                        ].unique()\n",
    "                                                    )\n",
    "                                                ],\n",
    "                                                style=dict(width=\"100%\"),\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row([html.H5(\"Table:\", className=\"text-info\")]),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            dcc.Dropdown(\n",
    "                                                id=\"dpdn6\",\n",
    "                                                multi=True,\n",
    "                                                clearable=True,\n",
    "                                                options=[\n",
    "                                                    {\n",
    "                                                        \"label\": name,\n",
    "                                                        \"value\": name,\n",
    "                                                    }\n",
    "                                                    for name in list(\n",
    "                                                        columns_csv[\n",
    "                                                            \"table_name\"\n",
    "                                                        ].unique()\n",
    "                                                    )\n",
    "                                                ],\n",
    "                                                style=dict(width=\"100%\"),\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            html.H5(\n",
    "                                                \"Select Network Layout:\",\n",
    "                                                className=\"text-info\",\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            dcc.Dropdown(\n",
    "                                                id=\"dpdn1\",\n",
    "                                                value=\"preset\",\n",
    "                                                clearable=False,\n",
    "                                                options=[\n",
    "                                                    {\n",
    "                                                        \"label\": name.capitalize(),\n",
    "                                                        \"value\": name,\n",
    "                                                    }\n",
    "                                                    for name in [\n",
    "                                                        \"breadthfirst\",\n",
    "                                                        \"grid\",\n",
    "                                                        \"random\",\n",
    "                                                        \"circle\",\n",
    "                                                        \"cose\",\n",
    "                                                        \"concentric\",\n",
    "                                                    ]\n",
    "                                                ],\n",
    "                                                style=dict(width=\"100%\"),\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            html.H5(\n",
    "                                                \"Select Neighbors Distance:\",\n",
    "                                                className=\"text-info\",\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            dcc.Dropdown(\n",
    "                                                id=\"dpdn2\",\n",
    "                                                value=1,\n",
    "                                                clearable=False,\n",
    "                                                options=[\n",
    "                                                    {\n",
    "                                                        \"label\": name,\n",
    "                                                        \"value\": name,\n",
    "                                                    }\n",
    "                                                    for name in [\n",
    "                                                        1,\n",
    "                                                        2,\n",
    "                                                        3,\n",
    "                                                    ]\n",
    "                                                ],\n",
    "                                                style=dict(width=\"100%\"),\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            html.Button(\n",
    "                                                \"Update\",\n",
    "                                                id=\"update-button\",\n",
    "                                                className=\"mr-3\",\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                ]\n",
    "                            ),\n",
    "                            width=3,\n",
    "                        ),\n",
    "                        dbc.Col(\n",
    "                            [\n",
    "                                dbc.Container(\n",
    "                                    cyto.Cytoscape(\n",
    "                                        id=\"cytoscape-node\",\n",
    "                                        layout={\"name\": \"preset\"},\n",
    "                                        style={\n",
    "                                            \"width\": \"100%\",\n",
    "                                            \"height\": \"500px\",\n",
    "                                        },\n",
    "                                        elements=elements_dash,\n",
    "                                        stylesheet=stylesheets,\n",
    "                                    )\n",
    "                                )\n",
    "                            ],\n",
    "                            width=5,\n",
    "                        ),\n",
    "                        dbc.Col(\n",
    "                            dbc.Container(\n",
    "                                [\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            html.H5(\n",
    "                                                \"Connection description:\",\n",
    "                                                className=\"text-info\",\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                    dbc.Row(\n",
    "                                        [\n",
    "                                            html.Pre(\n",
    "                                                id=\"cytoscape-tapEdgeData-json\",\n",
    "                                                style=styles[\"pre\"],\n",
    "                                            )\n",
    "                                        ]\n",
    "                                    ),\n",
    "                                ]\n",
    "                            ),\n",
    "                            width=2,\n",
    "                        ),\n",
    "                        dbc.Col(width=1),\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div([dbc.Row([html.Br([])])]),\n",
    "        html.Div(\n",
    "            [\n",
    "                dbc.Row(\n",
    "                    [\n",
    "                        dbc.Col(width=1),\n",
    "                        dbc.Col(\n",
    "                            dbc.Container([\n",
    "                                dbc.Row([html.H5(\"Database size:\", className=\"text-info\")]),\n",
    "                                dbc.Row([\n",
    "                            dash_table.DataTable(\n",
    "                                id=\"table2\",\n",
    "                                columns=[{\"name\": i, \"id\": i} for i in stats.columns],\n",
    "                                data=stats.to_dict(\"records\"),\n",
    "                            ),\n",
    "                                ])]),\n",
    "                            width=2),\n",
    "                        \n",
    "                            \n",
    "                        dbc.Col(width=1),\n",
    "                        dbc.Col(\n",
    "                            dbc.Container([dcc.Graph(id=\"my-graph\")]),\n",
    "                            width=8,\n",
    "                        ),\n",
    "                        \n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div([dbc.Row([html.Br([])])]),\n",
    "        html.Div(\n",
    "            [\n",
    "                dbc.Row(\n",
    "                    [\n",
    "                        dbc.Col(width=5),\n",
    "                        dbc.Col(\n",
    "                            html.H5(\n",
    "                                \"Table Preview\",\n",
    "                                className=\"text-info\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div([dbc.Row([html.Br([])])]),\n",
    "        html.Div(\n",
    "            [\n",
    "                dbc.Row(\n",
    "                    [\n",
    "                        dbc.Col(width=1),\n",
    "                        dbc.Col(\n",
    "                            dbc.Container(\n",
    "                                [\n",
    "                                    html.Table(\n",
    "                                        id=\"table\",\n",
    "                                        className=\"dbc_light\",\n",
    "                                    )\n",
    "                                ]\n",
    "                            ),\n",
    "                        ),\n",
    "                        dbc.Col(width=1),\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Schema Table selection\n",
    "\n",
    "\n",
    "@app.callback(Output(\"dpdn6\", \"options\"), [Input(\"dpdn5\", \"value\")])\n",
    "def update_tables(selected_schema):\n",
    "\n",
    "    if selected_schema == None:\n",
    "        df = columns_csv\n",
    "        return [\n",
    "            {\"label\": name, \"value\": name} for name in list(df[\"table_name\"].unique())\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        df = df_table3[df_table3[\"schema\"].isin(selected_schema)]\n",
    "        return [\n",
    "            {\"label\": name, \"value\": name} for name in list(df[\"from\"].unique())\n",
    "        ]\n",
    "\n",
    "\n",
    "# -  Network Format using the dropdown menu\n",
    "\n",
    "\n",
    "@app.callback(Output(\"cytoscape-node\", \"layout\"), Input(\"dpdn1\", \"value\"))\n",
    "def update_layout(layout_value):\n",
    "    if layout_value == \"breadthfirst\":\n",
    "        return {\"name\": layout_value, \"animate\": True}\n",
    "    else:\n",
    "        return {\"name\": layout_value, \"animate\": True}\n",
    "\n",
    "\n",
    "# Network Neighbors degrees\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"cytoscape-node\", \"elements\"),\n",
    "    [Input(\"update-button\", \"n_clicks\")],\n",
    "    [\n",
    "        State(\"cytoscape-node\", \"elements\"),\n",
    "        State(\"dpdn6\", \"value\"),\n",
    "        State(\"dpdn2\", \"value\"),\n",
    "    ],\n",
    ")\n",
    "def keep_nodes(_, elements, data, relation_value=1):\n",
    "    if data is None:\n",
    "        return no_update\n",
    "    else:\n",
    "\n",
    "        radius = relation_value\n",
    "        D = ego_graph(\n",
    "            G, data[0], radius=radius, center=True, undirected=False, distance=None\n",
    "        )\n",
    "        elements = nx.cytoscape_data(D)\n",
    "        nodes = elements[\"elements\"][\"nodes\"]\n",
    "\n",
    "        for i in range(len(nodes)):\n",
    "            a = nodes[i][\"data\"][\"id\"]\n",
    "            b = {\"position\": {\"x\": 1000 * pos[a][0], \"y\": 1000 * pos[a][1]}}\n",
    "            nodes[i].update(b)\n",
    "        for i in range(len(nodes)):\n",
    "            c = {\"selectable\": True}\n",
    "            nodes[i][\"data\"].update(c)\n",
    "        edges = elements[\"elements\"][\"edges\"]\n",
    "        for i in range(len(nodes)):\n",
    "            d = {\"color_node\": col_swatch[i]}\n",
    "            nodes[i][\"data\"].update(d)\n",
    "        edges = elements[\"elements\"][\"edges\"]\n",
    "        elements_dash = nodes + edges\n",
    "        return elements_dash\n",
    "    return elements\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"cytoscape-tapEdgeData-json\", \"children\"),\n",
    "    Input(\"cytoscape-node\", \"tapEdgeData\"),\n",
    ")\n",
    "def displayTapNodeData(data):\n",
    "    return json.dumps(data, indent=2)\n",
    "\n",
    "\n",
    "@app.callback(Output(\"my-graph\", \"figure\"), Input(\"dpdn6\", \"value\"))\n",
    "def update_nodes(data):\n",
    "    \n",
    "    if data is None:\n",
    "        return no_update\n",
    "\n",
    "    else:\n",
    "        label = data[0]\n",
    "        dff = columns_csv[columns_csv[\"table_name\"] == label]\n",
    "        fig = px.bar(\n",
    "            dff,\n",
    "            x=\"column_name\",\n",
    "            y=\"percentage\",\n",
    "            title=\"Percentage of filled data per column in: {}\".format(label),\n",
    "            color_discrete_sequence=[\"indianred\", \"RebeccaPurple\", \"darkgreen\"],\n",
    "        )\n",
    "        fig.update_xaxes(categoryorder=\"total descending\")\n",
    "        fig.add_hline(y=100)\n",
    "        fig.update_layout(template=\"plotly_white\", showlegend=False)\n",
    "        fig.update_traces(marker_line_color=\"RebeccaPurple\", marker_line_width=1.5)\n",
    "        return fig\n",
    "\n",
    "\n",
    "# - Show first 10 lines of selected table\n",
    "\n",
    "\n",
    "@app.callback(Output(\"table\", \"children\"), \n",
    "              [Input(\"update-button\", \"n_clicks\")],\n",
    "              [\n",
    "                State(\"dpdn5\", \"value\"),\n",
    "                State(\"dpdn6\", \"value\")\n",
    "              ]\n",
    "            )\n",
    "\n",
    "def table(_,schema_name,table_name):\n",
    "    \n",
    "    if schema_name is None:\n",
    "        return no_update\n",
    "    if table_name is None:\n",
    "        return no_update\n",
    "    \n",
    "    else:\n",
    "        query4_first10 = \"\"\"select * from {}.{} WHERE ROWNUM <= 10\"\"\".format(schema_name[0],table_name[0])\n",
    "        df = query_wo_header(query4_first10.format(j, k))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #table = data[0] + \"_rows\"\n",
    "        #dff5 = rows_tables[table]\n",
    "        table = dash_table.DataTable(\n",
    "            columns=[{\"name\": i, \"id\": i} for i in sorted(df.columns)],\n",
    "            data=df.to_dict(\"records\"),\n",
    "        )\n",
    "        return table\n",
    "\n",
    "\n",
    "app.run_server(port=8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbexplorer",
   "language": "python",
   "name": "dbexplorer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
